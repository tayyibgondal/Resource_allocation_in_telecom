{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "neD2zsPx_MdI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install triton\n",
        "!pip install xformers\n",
        "!pip install trl\n",
        "!pip install peft\n",
        "!pip install faiss-gpu\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGTd7ukrT4sV",
        "outputId": "18ad193d-8646-4ee0-8be7-47e18b2f047e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2024.10.2-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth-zoo (from unsloth)\n",
            "  Downloading unsloth_zoo-2024.10.2-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.4.1+cu121)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.0.28.post1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.8.12)\n",
            "Requirement already satisfied: transformers<4.45.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.44.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.0.1)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.34.2)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.24.7)\n",
            "Collecting hf-transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0->unsloth) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0->unsloth) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (13.9.2)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (1.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Downloading unsloth-2024.10.2-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2024.10.2-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: hf-transfer, trl, unsloth-zoo, unsloth\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.11.4\n",
            "    Uninstalling trl-0.11.4:\n",
            "      Successfully uninstalled trl-0.11.4\n",
            "Successfully installed hf-transfer-0.1.8 trl-0.11.1 unsloth-2024.10.2 unsloth-zoo-2024.10.2\n",
            "Found existing installation: unsloth 2024.10.2\n",
            "Uninstalling unsloth-2024.10.2:\n",
            "  Successfully uninstalled unsloth-2024.10.2\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-n1e2cj3e/unsloth_fcb40751ea1c4115aeeb963e71a2315f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-n1e2cj3e/unsloth_fcb40751ea1c4115aeeb963e71a2315f\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 3085f4c3daacc63939e78e3c87759d0d03c5a71f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth-zoo in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.12)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.7)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.2)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.1+cu121)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.10.2-py3-none-any.whl size=162348 sha256=b2363fdfc3d7adf7b82d24cf76eef7d39fae795149779d8b8f5c58b750377c7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pjyklwsh/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "Successfully installed unsloth-2024.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e6jOcR49Pqib",
        "outputId": "a867906e-37f3-4464-a68d-b4a451aa74cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPc-GapiWyLI"
      },
      "source": [
        "## Load the LLM that'll later be used for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "2cf6e4acc89f400284cb0857abd8d5ea",
            "30d05dd3128d43a9aea1301af2d17713",
            "88993c523bd64df1a9efef624e0513d5",
            "a58a4cbdb0f14e419ddc15a24fc3655d",
            "95aafb9d31f242cd835b548608706600",
            "23acf9fb30c14fbea5d819328767a6c6",
            "6f1b73855d67479281485171af845fe3",
            "43cfa86b42d8416898039b95155803b4"
          ]
        },
        "id": "60j_RDj1OTKi",
        "outputId": "0607dd41-0bad-4f37-ad25-320f1b369acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2024.10.2: Fast Llama patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cf6e4acc89f400284cb0857abd8d5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30d05dd3128d43a9aea1301af2d17713",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/140 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88993c523bd64df1a9efef624e0513d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.37k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58a4cbdb0f14e419ddc15a24fc3655d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95aafb9d31f242cd835b548608706600",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23acf9fb30c14fbea5d819328767a6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f1b73855d67479281485171af845fe3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
            "Please update transformers via:\n",
            "`pip uninstall transformers -y && pip install --upgrade --no-cache-dir \"git+https://github.com/huggingface/transformers.git\"`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43cfa86b42d8416898039b95155803b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/120M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.10.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 100 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"tayyibsupercool/Phi_3.5_mini-resource_allocation-energy_efficiecy_instruct_10k\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = True,\n",
        "    token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOT3BMfvjlIO"
      },
      "source": [
        "## Convert HuggingFace training dataset to a .txt file for easier vectorisation (this step isn't needed if you already have the ee_data_txt.txt file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UoWQkSfV8IB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load a dataset\n",
        "dataset = load_dataset(\"tayyibsupercool/resource_allocation_telecom_energy_efficiency_instruct\", split = \"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBADToXaUkHJ"
      },
      "outputs": [],
      "source": [
        "ee_filename = \"ee_data_txt.txt\"\n",
        "# Define a function to save data to a text file\n",
        "def save_to_txt(data, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    for item in data:\n",
        "      f.write(item['input'] + \" then B is \" + item['output'] + \"\\n\")\n",
        "\n",
        "# Save the training data to a text file\n",
        "save_to_txt(dataset, ee_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCakqUZqvXD0"
      },
      "source": [
        "## Creating embeddings from the .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "279yxybfJqU5",
        "outputId": "23994497-b721-4277-f949-e14998165e9e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa28430097794ab4ad9d4fd0833e6282",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e638b9e38a24cae99531caec411200c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "893f3e3eb009450aba2084f858337b94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "733adb587cbf4e43976e9176b52cc566",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86d3add25db04723aee990d6799df616",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c49ae621f3e3415dbcb83d7f81c17201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d287653b1665410ab966a38c596f87b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00e9a16da29b4313ac4c9a11ad9ce929",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d3371bd53a4f1182b6c1abb5a19f73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e1b423df81243dd9df01f11eab32e9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4acd056ff20946cfa845aae124a91f32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embeddings_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5m3IRv-BEOV"
      },
      "outputs": [],
      "source": [
        "# convert data to a list of lines\n",
        "ee_filename = \"ee_data_txt.txt\"\n",
        "\n",
        "with open(ee_filename, 'r') as f:\n",
        "    lines = [line.strip() for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdMiSgtBQzSy"
      },
      "outputs": [],
      "source": [
        "# vectorise every line\n",
        "embeddings = embeddings_model.encode(lines, normalize_embeddings='True')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMVZp1l-AULZ"
      },
      "outputs": [],
      "source": [
        "row_indices = np.arange(len(lines))  # Row indices\n",
        "np.save('row_indices.npy', row_indices)  # Save row indices separately for later use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ng2LtKmZhhm"
      },
      "source": [
        "## Generate FAISS index for the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnZ2oU25ZkvD"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "index.add(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiVf-OfAXDVA"
      },
      "source": [
        "## Save the embeddings to a .csv file (you don't need to run these cells if you don't want to save the embeddings - the rest of the code will work regardless of whether or not you run these cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQUCeFk4BPMK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "# Save row indices and embeddings to a CSV file\n",
        "with open('ee_embeddings_with_indices.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for idx, embedding in enumerate(embeddings):\n",
        "        writer.writerow([idx] + list(embedding))  # Write the index followed by the embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma6yzBaQHZ5S"
      },
      "outputs": [],
      "source": [
        "# run this only if using embeddings from csv file\n",
        "ee_csv_embeddings = []\n",
        "with open('ee_embeddings_with_indices.csv', newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        ee_csv_embedding = [float(x) for x in row[1:]]  # First column is index, rest are embeddings\n",
        "        ee_csv_embeddings.append(ee_csv_embedding)\n",
        "\n",
        "import faiss\n",
        "\n",
        "embedding_dim = ee_csv_embeddings.shape[1]\n",
        "index_csv = faiss.IndexFlatIP(embedding_dim)\n",
        "index_csv.add(np.array(ee_csv_embeddings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bdvsOuxYelf"
      },
      "source": [
        "## Creating the augmented dataset with retrieved context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk4JhTReYG3U"
      },
      "source": [
        "Load the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "v9gt7OjQLoxk",
        "outputId": "72fb348d-3fa5-4759-cd10-e8b6234e8059"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c031c64a68d442b914bc8617c7c0ba6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "881dade0320f4256a5b5e0a46ac83153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cf380155d4f436fb064912cb64b3746",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/266k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d3ee901c7204b32acc305ac602a59de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/90000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "485abc2e0e6548ec8ceb8b26aa3c0e5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "validation_dataset = load_dataset(\"tayyibsupercool/resource_allocation_telecom_energy_efficiency_instruct\", split=\"validation[:1000]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc64lKsaL4LR"
      },
      "outputs": [],
      "source": [
        "def add_context(data):\n",
        "    # Implement your similarity search and retrieval logic here\n",
        "    input_embedding = embeddings_model.encode([data['input']], normalize_embeddings=True)\n",
        "    distances, indices = index.search(input_embedding, k)  # indices will give the closest vectors\n",
        "    # Load row indices\n",
        "    row_indices = np.load('row_indices.npy')\n",
        "    # Retrieve the original rows corresponding to the indices\n",
        "    similar_rows = [lines[row_indices[i]] for i in indices[0]]  # Get the original rows\n",
        "    data['context'] = \"\\n\".join(similar_rows)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "4XK6FyWB4eJF",
        "outputId": "f7f1fdd4-866f-4a55-f8ac-0221d6864169"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8b39a58721e4fcfad685c76b4705c23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "k=300 # number of similar vectors\n",
        "augmented_dataset = validation_dataset.map(add_context) # retrieve context fotr all examples in the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "z4Ix9ohDXN_u",
        "outputId": "1ecc0613-f91d-4019-8d16-a8fbf7eaac92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fd1ed70ff1f44369749c5ad3ff471a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6db12d057a84263b2e6b0574e03d2b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6abb8baeaa742b889eb35ebf6382532",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/aamina/channel_gains_vs_tx_powers_ee_augmented_with_30_examples_context_10k/commit/010de34ff7eec96c9d35b94a152d87017f018ac8', commit_message='Upload dataset', commit_description='', oid='010de34ff7eec96c9d35b94a152d87017f018ac8', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save the augmented dataset to huggingface\n",
        "from huggingface_hub import login\n",
        "login('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')\n",
        "augmented_dataset.push_to_hub(\"aamina/channel_gains_vs_tx_powers_ee_augmented_with_30_examples_context_10k\", private=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNGBSoZtpwRn"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "d7194a4f39064e0b83337f070742ca22",
            "9480b6a10d044f278ae65b115bff86ba",
            "f23100e605434d8791d752066ee125ba"
          ]
        },
        "id": "fglg5SFUZppW",
        "outputId": "c1f5904c-86db-4b86-f967-e3226626dea5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7194a4f39064e0b83337f070742ca22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/448 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9480b6a10d044f278ae65b115bff86ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f23100e605434d8791d752066ee125ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# get the validation dataset with retrieved context\n",
        "from datasets import load_dataset\n",
        "augmented_dataset = load_dataset(\"aamina/channel_gains_vs_tx_powers_ee_augmented_with_300_examples_context\", split=\"validation[:1000]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR3wkTcKX-gc"
      },
      "source": [
        "Format the promt for the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fM45ueElLkxC"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Context:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eKGaItMVo-IY"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    contexts      = examples[\"context\"]\n",
        "    texts = []\n",
        "    for instruction, input, context, output in zip(instructions, inputs, contexts, outputs):\n",
        "      # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "      text = alpaca_prompt.format(instruction, input, context, output) + EOS_TOKEN\n",
        "      texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "d8f58f80eddc423db41bf28cfe6e2001"
          ]
        },
        "id": "nsfxwEcUQAVs",
        "outputId": "e8c901ea-8d20-4e87-d675-1f170f0a201c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8f58f80eddc423db41bf28cfe6e2001",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "augmented_dataset = augmented_dataset.map(formatting_prompts_func, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYUMJbOaQLeX",
        "outputId": "769d0187-d50c-4caa-db26-a91f86d5d044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Take a deep breath and work on this problem step-by-step. You are a mathematical tool to predict some model. Your job is to predict B for given A. The following is the dataset that you can use for the prediction.\n",
            "['4178', '64389', '94069', '68863', '53558', '1146', '29213', '98256', '14453', '43953', '54906', '93598', '20436', '91465', '75309', '71488', '29873', '14016', '60494', '300', '57020', '10645', '7732', '51602', '93713', '14735', '47911', '15607', '23539', '42841', '16276', '66576', '75200', '37826', '64521', '63365', '95245', '74966', '39160', '85814', '85257', '35546', '26712', '78168', '73656', '71464', '48397', '4640', '9975', '2888', '49234', '57167', '18293', '65529', '71302', '89901', '40393', '16844', '92329', '30319', '70154', '17698', '92993', '47059', '77267', '42440', '7642', '74139', '77159', '18922', '35336', '48038', '35069', '55896', '95508', '92395', '86071', '38052', '66318', '90286', '48459', '62748', '38981', '7568', '81161', '55573', '84293', '73898', '88002', '31863', '81815', '64620', '37428', '91588', '4544', '62393', '4014', '95477', '81948', '88125', '58730', '72561', '392', '27239', '14437', '97929', '5869', '87157', '66141', '85071', '88649', '56623', '64650', '30847', '82022', '30166', '46219', '52469', '60398', '83319', '26702', '60827', '51468', '27694', '55119', '785', '8700', '96249', '9294', '27329', '75588', '37736', '15006', '83311', '56972', '67027', '94693', '34549', '26158', '98855', '39856', '78126', '80460', '63661', '48572', '89973', '15400', '79618', '49052', '21981', '76777', '93682', '41289', '44345', '65310', '74567', '77218', '3426', '26188', '90149', '38131', '89975', '84487', '5106', '19967', '38346', '67336', '29784', '41049', '15406', '40013', '77397', '73545', '46350', '53830', '20818', '69316', '38310', '41725', '86636', '87032', '35406', '74882', '28602', '69405', '51026', '66475', '94153', '67870', '91876', '14613', '34752', '42962', '35448', '6553', '10013', '31675', '45950', '38427', '26422', '76806', '45593', '66077', '89459', '86891', '4234', '99881', '61983', '76909', '74740', '66253', '34523', '9006', '12964', '14103', '81503', '21349', '64126', '13839', '92785', '13251', '9000', '92592', '53603', '5266', '25105', '20707', '59505', '54909', '77688', '71218', '53823', '38433', '21969', '96908', '71878', '1401', '11416', '82581', '77628', '17675', '91203', '61122', '54217', '8669', '81706', '37804', '3972', '22408', '60576', '45180', '52699', '72920', '14169', '12177', '51718', '54667', '40569', '64688', '15250', '23138', '42462', '63087', '53326', '4854', '94987', '63024', '75131', '40276', '69081', '16332', '52676', '86799', '43191', '93134', '23757', '38476', '78371', '74777', '71380', '22737', '27250', '21287', '23583', '24183', '49307', '22224', '55953', '61566', '12829', '54841', '58437', '43835', '928', '36036', '46183', '90363', '30557', '63202', '96347', '73636', '22986', '38128', '3227', '45926', '62816', '17352', '59575', '87807', '16216', '65830', '23965', '29517', '64587', '30994', '55983', '72848', '27880', '21149', '52120', '22188', '70736', '65941', '81994', '52784', '90156', '35535', '18679', '52190', '13577', '68645', '52828', '70864', '29758', '16184', '50927', '28040', '6234', '99244', '77198', '28196', '45883', '46867', '4975', '36627', '46205', '96614', '33715', '55136', '47717', '86012', '39925', '30776', '94071', '44985', '5255', '4663', '76631', '77188', '71319', '399', '22032', '31394', '62361', '17606', '55910', '64920', '46805', '12265', '16823', '32118', '25285', '60391', '45711', '80152', '11548', '189', '98275', '76905', '48548', '23381', '33745', '72655', '33525', '81504', '82398', '27277', '36227', '18742', '87195', '78909', '30888', '94169', '11971', '24237', '53669', '59498', '16490', '8439', '8400', '98742', '88309', '7389', '72240', '60678', '84860', '15312', '89787', '10804', '13580', '12936', '4921', '19450', '72192', '58465', '4906', '58082', '47514', '41477', '2200', '1646', '81691', '41870', '34249', '83178', '60613', '216', '11425', '65883', '68522', '41108', '32523', '55315', '42971', '7155', '17063', '97967', '19173', '85952', '84084', '54463', '79999', '7638', '20231', '64172', '94168', '65906', '3761', '74343', '48592', '23225', '82027', '10888', '53302', '65930', '35763', '98104', '42960', '95502', '98344', '12546', '38381', '9137', '72203', '73692', '55781', '36290', '57717', '46582', '31440', '19304', '53339', '52003', '23097', '81160', '63126', '28375', '62721', '66168', '24805', '98331', '72726', '32162', '63962', '19227', '33130', '20578', '46527', '55212', '62272', '47136', '61040', '97393', '37990', '96890', '67290', '40895', '7257', '74345', '80054', '92543', '85011', '76940', '54611', '48599', '90011', '43049', '62228', '21519', '24926', '83348', '78347', '6177', '96904', '84611', '81400', '76211', '72040', '66981', '16515', '3033', '8201', '53513', '95905', '35740', '74970', '51024', '35581', '96074', '60207', '89520', '11714', '39031', '98139', '80323', '24586', '57087', '72527', '16475', '6988', '16737', '59504', '99171', '82807', '31302', '69597', '35396', '56858', '68310', '7997', '495', '74643', '21473', '82810', '96589', '15530', '94718', '64656', '45080', '96073', '28464', '65788', '38034', '88852', '89728', '69904', '65408', '94060', '86370', '40356', '71413', '88567', '6061', '7901', '37169', '59686', '72988', '33275', '28957', '85465', '42831', '22079', '84343', '76970', '16696', '20670', '1513', '60090', '53599', '55506', '1550', '29387', '62517', '27102', '22640', '50044', '7577', '84610', '97970', '76327', '78481', '11847', '45840', '96243', '6190', '51675', '34820', '11252', '37230', '13548', '60530', '34220', '47493', '95885', '40646', '4344', '28474', '58774', '8745', '30954', '41879', '91338', '16718', '3328', '26192', '21281', '86725', '67366', '42561', '44459', '89562', '33827', '84513', '58154', '7125', '80334', '88038', '40130', '59339', '94', '50799', '14854', '82885', '96778', '92224', '55257', '56343', '76308', '88584', '34646', '56880', '41663', '54309', '84777', '6647', '19847', '43070', '82927', '57331', '84007', '78782', '8764', '58770', '72627', '89085', '24946', '7419', '81042', '32323', '92000', '44599', '39847', '60461', '60291', '4110', '33550', '4794', '26276', '95085', '16902', '43343', '29659', '51897', '60722', '76261', '53970', '30132', '37320', '55057', '79205', '3160', '20072', '32453', '84550', '28598', '54109', '19295', '96040', '9653', '49244', '3318', '72634', '58027', '41701', '85403', '87576', '9779', '2021', '95543', '47808', '63020', '95735', '56155', '95242', '65994', '53457', '62438', '6564', '4763', '60074', '74916', '81058', '30381', '91753', '51855', '26539', '74702', '2169', '12647', '59835', '96041', '98132', '80577', '77036', '42898', '64257', '21005', '54036', '99525', '42562', '86723', '34668', '63085', '74573', '67322', '79819', '46797', '46600', '66192', '77289', '75726', '84267', '97685', '49845', '77622', '58862', '32822', '2576', '38266', '85466', '75392', '7767', '7542', '33269', '44343', '40225', '12577', '27067', '45123', '69344', '93488', '54985', '8351', '74142', '60282', '92116', '32563', '95151', '38115', '8320', '12743', '72747', '77017', '5283', '72520', '71797', '16046', '56794', '65025', '97247', '91050', '88817', '7512', '40640', '93720', '60223', '83108', '98232', '61383', '96662', '60437', '87800', '60844', '43672', '91858', '91854', '34077', '41069', '89950', '65318', '2496', '62587', '81917', '60236', '72076', '28873', '45937', '77247', '23341', '56241', '87114', '24846', '22528', '5124', '55818', '14831', '16085', '31691', '28307', '81057', '52810', '30293', '43085', '19810', '44369', '27793', '42882', '25561', '82514', '18930', '23725', '60734', '62107', '79987', '71385', '64481', '22216', '93460', '7591', '20106', '50785', '64414', '7180', '64083', '10793', '21613', '4580', '79022', '37674', '41030', '84368', '94445', '90547', '78915', '7718', '96316', '54219', '84885', '79349', '74833', '52552', '94158', '88427', '71525', '46031', '65622', '81749', '16320', '23109', '48712', '43912', '85657', '83714', '74759', '14335', '4300', '90413', '80922', '3664', '85215', '91364', '60940', '37033', '33867', '93719', '80605', '86500', '13943', '68227', '63097', '9760', '79169', '68256', '69431', '30793', '47829', '61796', '37298', '34014', '76150', '21894', '42466', '30637', '5557', '5213', '20504', '29217', '47592', '81662', '15600', '26619', '95610', '68052', '79746', '5304', '93960', '57012', '21709', '17428', '88352', '9799', '73701', '17296', '4469', '92808', '40093', '73850', '42888', '99970', '53526', '68175', '16914', '25485', '89435', '49047', '5669', '23766', '78838', '26792', '59622', '72051', '65912', '64011', '99468', '23520', '7650', '61923', '91454', '53461', '36346', '62657', '15209', '56844', '95092', '86549', '35916', '36539', '3827', '5286', '92157', '55335', '12338', '68625', '9340', '19640', '71032', '64475', '57686', '20443', '77573', '73348', '62448', '16886', '59296', '5129', '34616', '36398', '53900', '84732', '46366', '99991', '81006', '17812', '78381', '7842', '38753', '38940', '99412', '38620', '80187']\n",
            "#INPUT \n",
            "If A is -56, -352, -172, -32, \n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "# Print the result\n",
        "print(augmented_dataset[\"instruction\"][0])\n",
        "print(augmented_dataset[\"sample_index\"])\n",
        "print(augmented_dataset[\"text\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5CUaSWZSiU2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm  # Import tqdm for the progress bar\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "\n",
        "# Set up for measuring inference time\n",
        "num_inferences = 100\n",
        "total_time = 0\n",
        "\n",
        "# List to store the results\n",
        "results = []\n",
        "\n",
        "\n",
        "# Inference loop with tqdm progress bar\n",
        "for i in tqdm(range(num_inferences), desc=\"Running Inference\"):\n",
        "    example = augmented_dataset[i]\n",
        "    input_texts = alpaca_prompt.format(example['instruction'], example['input'], example['context'], \"\")\n",
        "\n",
        "    # Tokenize the input (on CPU to save GPU memory)\n",
        "    inputs = tokenizer(input_texts, max_length=2048, truncation=True, return_tensors=\"pt\", padding=True).to(\"cpu\")\n",
        "\n",
        "    # Move inputs to GPU\n",
        "    inputs = {key: val.to(\"cuda\") for key, val in inputs.items()}\n",
        "\n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=10, use_cache=True)\n",
        "    end_time = time.time()\n",
        "\n",
        "    inference_time = end_time - start_time\n",
        "    total_time += inference_time\n",
        "    print(f\"Inference {i+1} took {inference_time:.4f} seconds\")\n",
        "\n",
        "# Calculate and print the average time\n",
        "average_time = total_time / num_inferences\n",
        "print(f\"\\nAverage inference time over {num_inferences} runs: {average_time:.4f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vOT3BMfvjlIO",
        "FCakqUZqvXD0",
        "_Ng2LtKmZhhm",
        "NiVf-OfAXDVA",
        "4bdvsOuxYelf"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}